{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Manteia AI Engineering Playbook \u2014 v0.1","text":"<p>Data: 2025-09-23</p> <p>Benvenuti nel playbook tecnico per il nuovo team AI di Manteia. Questo repository raccoglie linee guida, blueprint e template per costruire applicazioni AI/ML production-grade con approcci agili (SCRUM), CI/CD, architetture open-source e paradigmi moderni (ReAct agents, agentic RAG, LLM open-source, Model Context Protocol).</p>"},{"location":"#struttura","title":"Struttura","text":"<ul> <li><code>docs/</code> \u2013 manuali, policy, pratiche e blueprint architetturali</li> <li><code>.github/</code> \u2013 template per issue/PR e pipeline CI di esempio</li> </ul> <p>Per una panoramica rapida leggi docs/00-vision.md e docs/01-ways-of-working.md.</p>"},{"location":"00-vision/","title":"Visione, Missione e Valori Tecnici","text":"<p>Visione: Accelerare l'impatto del business Manteia con soluzioni AI affidabili, manutenibili e scalabili.</p> <p>Missione: Mettere in produzione sistemi AI moderni (agentic RAG, ReAct, LLM OSS, MCP) con un toolkit uniforme e processi ripetibili, dalla sperimentazione al rilascio.</p> <p>Valori Tecnici - Qualit\u00e0 prima della velocit\u00e0: test, revisione, osservabilit\u00e0 by default. - Semplicit\u00e0 deliberata: evitare complessit\u00e0 non necessarie, scegliere standard aperti. - Automazione: CI/CD, linting, security scan, data checks. - Trasparenza: ADR, metriche chiare, documentazione vicina al codice. - Responsible AI: valutazioni, guardrail, privacy, reproducibility.</p>"},{"location":"01-ways-of-working/","title":"Ways of Working (Scrum-based)","text":"<ul> <li>Eventi: Sprint (2 settimane), Daily (15'), Planning, Review, Retro.</li> <li>Artefatti: Product Backlog (epic/story), Sprint Backlog, Definition of Ready/Done.</li> <li>Policy PR: 1 feature = 1 PR piccola, code review obbligatoria, CI verde.</li> <li>Branching: trunk-based + feature branches (<code>feature/\u2026</code>, <code>fix/\u2026</code>, <code>chore/\u2026</code>).</li> <li>Issue Types: feature, bug, tech-debt, research spike.</li> <li>Definition of Done (DoD):</li> <li>Lint/format (pre-commit), test &gt;= 80% line coverage (quando sensato), type-check OK</li> <li>Docs aggiornate (CHANGELOG/README), ADR per decisioni chiave</li> <li>Observability: metrica/trace/log di base</li> </ul>"},{"location":"02-testing-strategy/","title":"Strategia di Test","text":"<p>Piramide 1. Unit (veloci, ~70%): funzioni, tool adapter, prompt template rendering deterministico. 2. Integration (~20%): DB, vector store, API esterne (test-containers/mocks). 3. E2E (~10%): percorsi critici, flussi agentici.</p> <p>Per LLM &amp; Agent - Golden tests: input=&gt;output atteso (con tolleranze). - Schema tests: JSON schema/Guardrails per risposte strutturate. - Adversarial suite: prompt injection, jailbreak, PII leak. - Eval: RAG accuracy (es. RAGAS), task success rate, hallucination rate, latency, cost.</p>"},{"location":"03-ci-cd/","title":"CI/CD","text":"<p>CI (per PR) - Lint/format (ruff, black, eslint), type-check (mypy/tsc) - Unit/Integration test (pytest, vitest), coverage report - Security scans: <code>bandit</code>, <code>pip-audit</code>/<code>npm audit</code>, <code>trivy</code> immagini - Build immagine Docker e sbarramento (OPA policy opzionale)</p> <p>CD - Staging automatica su merge in <code>main</code> - Canary/Blue-Green per servizi critici - Migrazioni DB automatizzate con rollback - Feature flags per rilasci progressivi</p> <p>Artifact Registry: container, wheel/npm, dataset snapshot (DVC), modelli (MLflow)</p>"},{"location":"04-mlops-llmops/","title":"MLOps / LLMOps per RAG, Agent e Modelli","text":"<ul> <li>Data Versioning: DVC/LakeFS; dataset card, lineage e checksum.</li> <li>Model Registry: MLflow o equivalente, con stage (Staging/Production) e metriche.</li> <li>Serving LLM OSS: vLLM/TGI, Ollama per dev locale; throttling e quota per tenant.</li> <li>Vector Store: Weaviate, Qdrant, PgVector; schemi, TTL, politica di re-embedding.</li> <li>Prompt Management: versioning, A/B Prompt, canary.</li> <li>Agent Eval: harness di scenari, tool-ablation, replay di conversazioni reali.</li> <li>Guardrail: PII scrubber, output schema, content policy, rate-limit adattivo.</li> </ul>"},{"location":"09-onboarding-checklist/","title":"Onboarding Checklist (New Joiner)","text":"<ul> <li>Accessi: repo, CI, registri artifact, vault, dashboard</li> <li>Dev env: SDK, pre-commit, container runtime</li> <li>Leggere: 00-vision, 01-ways-of-working, 02-testing, 03-ci-cd</li> <li>Fare: primo ticket \u201cGood first issue\u201d, aprire 1 PR</li> <li>Shadowing: 1 sprint con pair programming</li> </ul>"},{"location":"blueprints/10-agentic-arch-blueprint/","title":"Blueprint \u2014 Agentic RAG + ReAct","text":"<pre><code>flowchart LR\n  U[User] --&gt; GW(API Gateway)\n  GW --&gt; AG[Coordinator Agent (ReAct)]\n  AG --&gt;|Retrieve| RET[Retriever]\n  RET --&gt; VS[(Vector Store)]\n  AG --&gt;|Tools| T1[Search Tool] &amp; T2[Code Runner] &amp; T3[MCP Tools]\n  AG --&gt; LLM[LLM Runtime]\n  LLM --&gt; OBS[Telemetry: traces/metrics/logs]\n  AG --&gt; SVC[Domain Services]\n  SVC --&gt; DB[(DB)]\n</code></pre> <p>Punti chiave - Coordinator Agent con ReAct per plan/act/observe. - Retrieval ibrido (BM25 + dense) + re-ranking. - Tooling via MCP per discovery/handshake standard dei tool. - Osservabilit\u00e0 end-to-end (OpenTelemetry): latenza, token, tool error rate. - Policy di stop-condition e fallback (router su modelli diversi).</p>"},{"location":"blueprints/11-mcp-playbook/","title":"MCP (Model Context Protocol) \u2014 Playbook","text":"<ul> <li>Server: espone tool dichiarativi (manifest, schema input/output, auth).</li> <li>Client: agent/app che negozia capabilities e invoca tool.</li> <li>Contract: versionare manifest, backward compatibility, test di handshake.</li> <li>Sicurezza: scoping dei permessi (principle of least privilege), rate-limit per tool.</li> <li>Testing: simulare errori di rete/timeout; golden I/O per ogni tool.</li> </ul>"},{"location":"blueprints/12-rag-blueprint/","title":"Blueprint \u2014 Retrieval-Augmented Generation (RAG)","text":"<ul> <li>Ingest: pipeline chunking+embedding; qualit\u00e0 (dedup, PII scrub)</li> <li>Index: schema con metadati (source, timestamp, access level)</li> <li>Query: retriever ibrido + re\u2011ranker; caching</li> <li>Synthesis: template controllati, citazioni obbligatorie</li> <li>Eval: faithfulness, grounding rate, answer similarity, latency</li> </ul>"},{"location":"policies/05-security-privacy/","title":"Security, Privacy &amp; Compliance","text":"<ul> <li>Segreti: gestiti con vault; mai nel codice/CI logs.</li> <li>PII: classificazione dati, minimizzazione, mascheramento in log.</li> <li>SBOM: generare per ogni build (Syft), scan CVE (Grype).</li> <li>Supply Chain: pinning versioni, firma immagini (cosign), policy admission.</li> <li>Accessi: SSO, RBAC, audit trail.</li> </ul>"},{"location":"policies/07-data-prompt-governance/","title":"Data &amp; Prompt Governance","text":"<ul> <li>Dataset Card: origine, licenze, bias, limiti d\u2019uso.</li> <li>Prompt Card: scopo, rischi, esempi positivi/negativi, metriche.</li> <li>Retention: politiche su cronologia conversazioni e feedback utenti.</li> </ul>"},{"location":"policies/08-release-versioning/","title":"Release &amp; Versioning","text":"<ul> <li>SemVer (MAJOR.MINOR.PATCH)</li> <li>CHANGELOG obbligatorio</li> <li>Release Train: cadenza bisettimanale; hotfix fuori banda se P0/P1</li> </ul>"},{"location":"practices/06-observability/","title":"Observability","text":"<ul> <li>Metrics: p95 latency, throughput, error rate; token usage, hit/miss cache.</li> <li>Traces: OpenTelemetry su hop agentici e tool-invocation.</li> <li>Logs: strutturati (JSON), correlation id.</li> <li>Dashboards: SLO/SLI e alerting su canali on-call.</li> </ul>"},{"location":"practices/07-llm-testing-playbook/","title":"LLM Testing &amp; Evaluation Playbook","text":"<ul> <li>Contract tests per tool e formati (JSON schema)</li> <li>Content filters e red-teaming (prompt injection, policy bypass)</li> <li>Offline eval: suite di Q/A per RAG, metriche (precision@k, faithfulness)</li> <li>Online eval: A/B con feedback utente e guardrail runtime</li> <li>Canary: rollout graduale con kill-switch</li> </ul>"},{"location":"practices/coding-standards-python/","title":"Coding Standards \u2014 Python","text":"<ul> <li>Tooling: <code>ruff</code> (lint), <code>black</code> (format), <code>mypy</code> (types), <code>pytest</code> + <code>coverage</code>.</li> <li>Struttura: <code>src/&lt;package&gt;/...</code>, <code>tests/</code> mirror dei moduli, <code>pyproject.toml</code> centralizza config.</li> <li>Error Handling: eccezioni specifiche, no <code>except: pass</code>, log strutturati.</li> <li>Config: <code>pydantic</code> o <code>dynaconf</code>; disaccoppiare da env (12-factor).</li> <li>I/O: funzioni pure dove possibile, side-effects confinati.</li> <li>Prompt &amp; Templates: versionare i prompt come file (<code>.prompt.md</code>) con variabili esplicite.</li> </ul>"},{"location":"practices/coding-standards-typescript/","title":"Coding Standards \u2014 TypeScript/Node","text":"<ul> <li>Tooling: <code>eslint</code>, <code>prettier</code>, <code>tsc --noEmit</code>, <code>vitest/jest</code>.</li> <li>Layout: <code>src/</code> + <code>tests/</code>, path alias, strictNullChecks.</li> <li>API: Fastify/Express tipizzate; OpenAPI come contratto (zod/openapi).</li> <li>Security: <code>helmet</code>, rate-limit, input validation, JWT/OAuth2.</li> </ul>"},{"location":"runbooks/incident-response/","title":"Runbook \u2014 Incident Response","text":"<ol> <li>Triage: severit\u00e0, blast radius, canale di guerra, owner on-call</li> <li>Mitigazione: rollback/canary freeze, rate-limit</li> <li>Diagnosi: log/traces, ultime release, dipendenze</li> <li>Risoluzione: fix + test</li> <li>Postmortem: timeline, 5 whys, azioni correttive, owner e due-date</li> </ol>"},{"location":"template/13-adr-template/","title":"ADR-XXXX:  <ul> <li>Stato: Proposed</li> <li>Contesto:  <li>Decisione:  <li>Conseguenze:  <li>Alternative valutate:","text":""},{"location":"template/14-project-structure/","title":"Project Template \u2014 SoH Estimator (Refactor-style)","text":"<p>Struttura ispirata al Refactor SoH Estimator: moduli chiari, YAML configs, CLI Typer, training 2-stage, IC processing e subspace tracking (GROUSE/PAST), CI pronta.</p> <p>Scarica</p>"},{"location":"template/14-project-structure/#layout","title":"Layout","text":"<p>/ \u251c\u2500 README.md \u251c\u2500 pyproject.toml \u251c\u2500 .pre-commit-config.yaml \u251c\u2500 .gitignore \u251c\u2500 Makefile \u251c\u2500 configs/ \u2502 \u251c\u2500 default.yaml \u2502 \u251c\u2500 data/ \u2502 \u251c\u2500 model/ \u2502 \u2514\u2500 train/{pretrain.yaml,fine_tune.yaml} \u251c\u2500 src// \u2502 \u251c\u2500 init.py \u2502 \u251c\u2500 cli.py \u2502 \u251c\u2500 utils/{config.py,logging.py,paths.py} \u2502 \u251c\u2500 data/{datasets.py} \u2502 \u251c\u2500 models/ \u2502 \u251c\u2500 training/{lit_module.py,trainer.py,callbacks.py} \u2502 \u251c\u2500 eval/{metrics.py} \u2502 \u2514\u2500 plots/ \u251c\u2500 scripts/{run_train.sh,download_data.sh} \u251c\u2500 notebooks/ \u2502 \u251c\u2500 etl/.gitkeep \u2502 \u2514\u2500 model/.gitkeep \u251c\u2500 tests/ \u2502 \u251c\u2500 test_datasets.py \u2502 \u251c\u2500 test_models_shape.py \u2502 \u2514\u2500 test_cli.py \u2514\u2500 .github/workflows/ci.yml"},{"location":"template/14-project-structure/#cli-standard","title":"CLI standard","text":"<ul> <li><code>train</code>, <code>finetune</code>, <code>reconstruct</code>, <code>eval</code>, <code>plot</code>, <code>split</code>.</li> <li>Config a riga di comando: <code>--config configs/train/pretrain.yaml</code>.</li> </ul>"}]}